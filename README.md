# Candle Practice Application

[![Rust](https://img.shields.io/badge/rust-2021-orange.svg)](https://www.rust-lang.org/)
[![Candle](https://img.shields.io/badge/candle-0.9.1-blue.svg)](https://github.com/huggingface/candle)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Generated by Kiro](https://img.shields.io/badge/Generated%20by-Kiro%20AI-purple.svg)](https://kiro.ai)

> **🤖 This project was entirely generated by [Kiro AI](https://kiro.ai)** - An AI-powered development assistant that created this comprehensive Candle learning framework through iterative development and testing.

A comprehensive educational framework for learning and experimenting with the [Candle](https://github.com/huggingface/candle) deep learning library in Rust. This application provides hands-on exercises for tensor operations, matrix manipulations, and neural network fundamentals with automatic backend detection and performance monitoring.

## ✨ Features

- **🎯 Educational Exercise Framework**: Structured learning modules covering tensor basics, matrix operations, and neural networks
- **🚀 Automatic Backend Detection**: Seamless support for CUDA, Apple Metal, and CPU backends with intelligent fallback
- **📊 Performance Monitoring**: Built-in timing and metrics collection with nanosecond precision
- **🔧 Cross-Platform Support**: Works on Windows (CUDA), macOS (Metal), and Linux (CUDA/CPU)
- **📚 Interactive Learning**: Comprehensive examples with explanatory notes and demonstrations
- **⚡ GPU Acceleration**: Optimized for both NVIDIA CUDA and Apple Silicon GPUs

## 🏗️ Architecture

### Core Components

```
┌─────────────────────────────────────────────────────────────┐
│                    Main Application                         │
├─────────────────┬─────────────────┬─────────────────────────┤
│ Backend Manager │ Exercise        │ Performance Monitor     │
│                 │ Framework       │                         │
├─────────────────┼─────────────────┼─────────────────────────┤
│ • CUDA Support  │ • Tensor Basics │ • Nanosecond Timing    │
│ • Metal Support │ • Matrix Ops    │ • Metrics Collection   │
│ • CPU Fallback  │ • Neural Nets   │ • Backend Comparison   │
└─────────────────┴─────────────────┴─────────────────────────┘
```

### Backend Hierarchy
The application automatically detects and uses the best available backend:
1. **CUDA** (NVIDIA GPUs) - Highest priority
2. **Metal** (Apple Silicon) - macOS default
3. **CPU** (Multi-threaded) - Universal fallback

## 🚀 Quick Start

### Prerequisites

- **Rust 2021 Edition** or later
- **CUDA Toolkit** (optional, for NVIDIA GPU support)
- **Xcode Command Line Tools** (macOS, for Metal support)

### Installation

```bash
# Clone the repository
git clone https://github.com/buuuuuuug/candle_myapp.git
cd candle_myapp

# Build with default backend (Metal on macOS, CPU elsewhere)
cargo build

# Run the application
cargo run
```

### Backend-Specific Builds

```bash
# Build with CUDA support (requires CUDA toolkit)
cargo build --features cuda

# Build with Intel MKL optimization
cargo build --features mkl

# Build for CPU only
cargo build --no-default-features

# Release build for optimal performance
cargo build --release
```

## 📖 Usage Examples

### Basic Usage

```bash
# Run with automatic backend detection
cargo run

# Example output:
# 🚀 Candle Practice Application
# ===============================
# ✅ Using Metal backend
# 🔧 Backend Manager Status:
#    Backend: Metal
#    Details: Apple Metal GPU
#    Performance: 9670.80 ns (1000x1000 matrix multiplication)
```

### Available Exercises

The application includes three main categories of exercises:

#### 1. **Basic Tensors**
- **Tensor Creation**: Different data types and initialization methods
- **Tensor From Data**: Creating tensors from various data sources
- **Tensor Indexing and Slicing**: Element access and slicing operations
- **Advanced Slicing Patterns**: Complex indexing and selection techniques
- **Tensor Shape Manipulation**: Reshape, squeeze, unsqueeze operations

#### 2. **Matrix Operations**
- **Matrix Arithmetic**: Addition, subtraction, element-wise operations
- **Broadcasting Demonstrations**: Efficient tensor operations with different shapes

#### 3. **Neural Networks** *(Coming Soon)*
- Linear layers and weight initialization
- Activation functions (ReLU, Sigmoid, Tanh)
- Loss functions and training loops

### Performance Monitoring

All operations are automatically timed with nanosecond precision:

```
📊 Performance Metrics Summary:
   Backend: Metal
   Total Operations: 5

   🔧 tensor_creation:
      Executions: 1
      Average: 61333.00ns
      Throughput: 16304.44 ops/sec

   🔧 matrix_multiplication:
      Executions: 1
      Average: 594875.00ns
      Throughput: 1681.03 ops/sec
```

## 🏗️ Project Structure

```
candle_myapp/
├── src/
│   ├── main.rs                 # Application entry point
│   ├── backend.rs              # Backend detection and management
│   ├── exercise.rs             # Exercise framework foundation
│   ├── performance.rs          # Performance monitoring system
│   └── exercises/
│       ├── mod.rs              # Exercise module declarations
│       ├── tensor_basics.rs    # Fundamental tensor operations
│       └── matrix_operations.rs # Matrix arithmetic and broadcasting
├── .kiro/
│   ├── specs/                  # Kiro AI development specifications
│   └── steering/               # AI development guidance rules
├── Cargo.toml                  # Project configuration and dependencies
└── README.md                   # This file
```

### Key Modules

- **`backend.rs`**: Automatic device detection with CUDA → Metal → CPU fallback hierarchy
- **`exercise.rs`**: Trait-based exercise system with standardized results and metrics
- **`performance.rs`**: High-precision timing with statistical analysis and comparison tools
- **`exercises/`**: Modular exercise implementations covering tensor operations and matrix math

## 🔧 Configuration

### Feature Flags

Configure the build with different backend support:

```toml
[features]
default = ["metal"]           # Metal enabled by default (macOS)
cuda = ["candle-core/cuda"]   # NVIDIA CUDA support
metal = ["candle-core/metal"] # Apple Metal support
mkl = ["candle-core/mkl"]     # Intel MKL optimization
```

### Dependencies

```toml
[dependencies]
candle-core = { version = "0.9.1", features = ["metal"] }
candle-nn = "0.9.1"
anyhow = "1.0"              # Error handling
clap = "4.0"                # CLI interface
num_cpus = "1.0"            # CPU thread detection
```

## 🧪 Testing

Run the comprehensive test suite:

```bash
# Run all tests
cargo test

# Run tests with output
cargo test -- --nocapture

# Run specific test module
cargo test exercises::tensor_basics

# Run tests with specific backend
cargo test --features cuda
```

### Test Coverage

- **Backend Management**: Device detection and fallback mechanisms
- **Exercise Framework**: Exercise execution and result handling
- **Performance Monitoring**: Timing accuracy and metrics collection
- **Tensor Operations**: Mathematical correctness of all operations
- **Matrix Operations**: Broadcasting and arithmetic validation

## 🎯 Educational Goals

This application is designed to teach:

1. **Tensor Fundamentals**: Creation, manipulation, and indexing
2. **Matrix Operations**: Linear algebra operations essential for ML
3. **Broadcasting**: Efficient operations between different tensor shapes
4. **Performance Optimization**: Understanding backend capabilities and timing
5. **Rust ML Ecosystem**: Practical experience with Candle and Rust patterns

## 🤖 Generated by Kiro AI

This entire project was created through an iterative development process with [Kiro AI](https://kiro.ai), demonstrating:

- **Specification-Driven Development**: Requirements → Design → Implementation
- **Test-Driven Development**: Comprehensive test coverage from the start
- **Modular Architecture**: Clean separation of concerns and extensible design
- **Performance-First Approach**: Built-in monitoring and optimization
- **Cross-Platform Compatibility**: Automatic backend detection and fallback
- **Educational Focus**: Learning-oriented design with detailed explanations

### Development Process

1. **Requirements Analysis**: Defined comprehensive learning objectives
2. **Architecture Design**: Created modular, extensible framework
3. **Iterative Implementation**: Built features incrementally with testing
4. **Performance Optimization**: Integrated monitoring and backend selection
5. **Documentation**: Generated comprehensive guides and examples

## 🚧 Roadmap

- [ ] **Neural Network Exercises**: Linear layers, activation functions, training loops
- [ ] **Advanced Matrix Operations**: Eigenvalues, SVD, matrix decompositions
- [ ] **Model Examples**: Complete neural network implementations
- [ ] **Visualization**: Tensor and training visualization tools
- [ ] **Benchmarking Suite**: Comprehensive performance testing across backends
- [ ] **Interactive CLI**: Enhanced command-line interface with exercise selection

## 🤝 Contributing

This project serves as an educational example of AI-generated code. While primarily generated by Kiro AI, contributions are welcome:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- **[Candle](https://github.com/huggingface/candle)**: The excellent Rust deep learning framework
- **[Kiro AI](https://kiro.ai)**: The AI development assistant that generated this project
- **Rust Community**: For creating an amazing ecosystem for systems programming
- **Hugging Face**: For open-sourcing Candle and advancing ML accessibility

---

**⚡ Ready to explore tensor operations in Rust?** Run `cargo run` and start your Candle learning journey!